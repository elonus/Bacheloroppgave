---
title: "Bachelor"
author: "Andreas Matre"
date: "2/11/2020"
output: 
  pdf_document:
    toc: true
    number_sections: true
        #html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(survey)
library(ggplot2)
library(ggfortify)
library(cowplot)
```


When you want to make a model of some relationship between a response and predictors you generally first need to collect data to fit that model. This data can be collected in many different ways and it is very important to take into account the methods used in the information gathering when fitting models. In this paper I will show how to fit a linear regression model when your data is collected through a complex survey, a survey including unequal sampling probabilities, stratification and clustering. Definitions and details regarding what this means will come later in the paper. I will first start with a example illustrating what can go wrong if you do not take the methods used in the information gathering into account.


# Example

I will here show a simple example which illustrates what can happen if we do not take into account the sampling design when doing regression. In this example we have a dataset from a study which tried to show a relationship between the length of a persons left middle finger and their height. The dataset contains 200 samples, each containing the length of the persons left middle finger (cm), their height (inches) and the probability that they would be chosen for the sample.

In this case the researcher wanted a bigger sample of shorter people than tall people so they sampled with probabilities proportional to: 24 for people with height < 65, 12 for people with height = 65, 2 for people with height = 66 or 67 and 1 for people with height > 67.


This means that a disproportionately big part of the sample contains short people. 



```{r, include = FALSE}
anthsrs <- SDaA::anthsrs
anthuneq <- SDaA::anthuneq
anthuneq$weights <- 1/anthuneq$prob
```

To illustrate the difference, this first plot shows a random sample where every person had an equal chance of being included. The next plot shows the sample where short people had a higher chance of being included than tall people. As you can see the second plot is much more concentrated in the bottom of the plot.


```{r, echo = FALSE, warning = FALSE}
ggplot() + geom_point(data = anthsrs, aes(finger, height)) + ylim(60, 70) +
  theme(axis.title = element_text(size = 20),
        axis.text = element_text(size = 14))
```

```{r, echo = FALSE, warning = FALSE}
ggplot() + geom_point(data = anthuneq, aes(finger, height)) + ylim(60, 70) +
  theme(axis.title = element_text(size = 20),
        axis.text = element_text(size = 14))
```

This means that if you try to fit a linear regression model to the unequal probabilities sample the slope will tend to be smaller than what it should be, since there are few observations in the top right of the plot.

I will illustrate this now by fitting both a naive linear model and a model that takes into account the sampling probabilities.


```{r}
anthuneq.svy <- svydesign(ids = ~0, weights = ~weights, data = anthuneq)

normalmod <- lm(height ~ finger, data = anthuneq)
survmod <- svyglm(height ~ finger, design = anthuneq.svy)

normalcoef <- summary(normalmod)$coefficients
survcoef <- summary(survmod)$coefficients
```

```{r}
# Bootstrap
B = 10000

coefs <- sapply(1:B, function(x) {
  indeces <- sample(1:nrow(anthuneq), size = nrow(anthuneq), replace = TRUE)
  s <- anthuneq[indeces,]
  s.svy <- svydesign(ids = ~0, weights = ~weights, data = s)
  mod <- svyglm(height ~ finger, design = s.svy)
  return(summary(mod)$coefficients[,1])
})

intercept.var <- var(coefs[1,])
finger.var <- var(coefs[2,])
intercept.finger.cov <- cov(coefs[1,], coefs[2,])

```

```{r}
x.vals = seq(from = 10, to = 13, by = 0.1)
#predict.int.normalmod <- as.data.frame(predict(normalmod, newdata = data.frame(finger = x.vals), interval = "pred"))
#predict.int.normalmod$x.vals <- x.vals

normal.cov <- vcov(normalmod)
predict.normalmod <- predict(normalmod, newdata = data.frame(finger = x.vals))
predict.int.normalmod <- data.frame(fit = predict.normalmod)
predict.int.normalmod$x.vals <- x.vals
#predict.int.normalmod$se <- sqrt(intercept.var + predict.int.normalmod$x.vals^2 * finger.var + 2*predict.int.normalmod$x.vals * intercept.finger.cov)
predict.int.normalmod$se <- sqrt(summary(normalmod)$sigma^2 + cov.matrix[1, 1] + predict.int.normalmod$x.vals^2 * cov.matrix[2, 2] + 2*predict.int.normalmod$x.vals * cov.matrix[1, 2])
predict.int.normalmod$lwr <- predict.int.normalmod$fit - predict.int.normalmod$se * qt(0.975, df = nrow(anthuneq))
predict.int.normalmod$upr <- predict.int.normalmod$fit + predict.int.normalmod$se * qt(0.975, df = nrow(anthuneq))

cov.matrix <- vcov(survmod)

predict.survmod <- as.data.frame(predict(survmod, newdata = data.frame(finger = x.vals), se=TRUE))
predict.int.survmod <- data.frame(fit = predict.survmod$link)
predict.int.survmod$x.vals <- x.vals
#predict.int.survmod$se <- sqrt(intercept.var + predict.int.survmod$x.vals^2 * finger.var + 2*predict.int.survmod$x.vals * intercept.finger.cov)
predict.int.survmod$se <- sqrt(var(survmod$residuals) + cov.matrix[1, 1] + predict.int.survmod$x.vals^2 * cov.matrix[2, 2] + 2*predict.int.survmod$x.vals * cov.matrix[1, 2])
predict.int.survmod$lower <- predict.int.survmod$fit - predict.int.survmod$se * qt(0.975, df = nrow(anthuneq))
predict.int.survmod$upper <- predict.int.survmod$fit + predict.int.survmod$se * qt(0.975, df = nrow(anthuneq))
```


```{r}
#prop = 0.0001
#size.uneq <- ceiling(anthuneq$weights)
#size.uneq <- replace(size.uneq, size.uneq == 1384, prop * 1384)
#size.uneq <- replace(size.uneq, size.uneq == 2767, prop * 2767)
#size.uneq <- replace(size.uneq, size.uneq == 16584, prop * 16584)
#size.uneq <- replace(size.uneq, size.uneq == 33223, prop * 33223)

size.uneq <- rep(0.8, length(nrow(anthuneq)))
size.srs <- rep(0.8, length(nrow(anthuneq)))

base <- ggplot() + xlim(10, 13) + ylim(58, 72)

uneq.surv.plot <- base +
  geom_point(data = anthuneq, aes(finger, height), size = size.uneq) +
  geom_abline(slope = survcoef[2], intercept = survcoef[1], color = "blue", lwd = 1) +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = lower), color = "blue", linetype = "dashed") +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = upper), color = "blue", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))

uneq.normal.plot <- base +
  geom_point(data = anthuneq, aes(finger, height), size = size.uneq) +
  geom_abline(slope = normalcoef[2], intercept = normalcoef[1], color = "red", lwd = 1) +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = lwr), color = "red", linetype = "dashed") +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = upr), color = "red", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))

srs.surv.plot <- base +
  geom_point(data = anthsrs, aes(finger, height), size = size.srs) +
  geom_abline(slope = survcoef[2], intercept = survcoef[1], color = "blue", lwd = 1) +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = lower), color = "blue", linetype = "dashed") +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = upper), color = "blue", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))

srs.normal.plot <- base +
  geom_point(data = anthsrs, aes(finger, height), size = size.srs) +
  geom_abline(slope = normalcoef[2], intercept = normalcoef[1], color = "red", lwd = 1) +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = lwr), color = "red", linetype = "dashed") +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = upr), color = "red", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))

plot_grid(uneq.normal.plot, uneq.surv.plot, srs.normal.plot, srs.surv.plot, ncol = 2, labels = "AUTO")
```


```{r}
size.uneq <- rep(0.8, length(nrow(anthuneq)))
size.srs <- rep(0.8, length(nrow(anthuneq)))

base <- ggplot() + xlim(10, 13) + ylim(58, 72)

uneq.plot <- base +
  geom_point(data = anthuneq, aes(finger, height), size = size.uneq) +
  geom_abline(slope = survcoef[2], intercept = survcoef[1], color = "blue", lwd = 1) +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = lower), color = "blue", linetype = "dashed") +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = upper), color = "blue", linetype = "dashed") +
  geom_abline(slope = normalcoef[2], intercept = normalcoef[1], color = "red", lwd = 1) +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = lwr), color = "red", linetype = "dashed") +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = upr), color = "red", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))

srs.plot <- base +
  geom_point(data = anthsrs, aes(finger, height), size = size.srs) +
  geom_abline(slope = survcoef[2], intercept = survcoef[1], color = "blue", lwd = 1) +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = lower), color = "blue", linetype = "dashed") +
  geom_line(data = predict.int.survmod, aes(x = x.vals, y = upper), color = "blue", linetype = "dashed") +
  geom_abline(slope = normalcoef[2], intercept = normalcoef[1], color = "red", lwd = 1) +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = lwr), color = "red", linetype = "dashed") +
  geom_line(data = predict.int.normalmod, aes(x = x.vals, y = upr), color = "red", linetype = "dashed") +
  theme(axis.title.x = element_text(size = 20))


plot_grid(uneq.plot, srs.plot, nrow = 2, labels = "AUTO")
```


We can see in the code that in the model which takes the unequal sampling probabilities into account we first define a design object which in addition to the covariates includes information about the probabilities of each observation being chosen. Here we use a value called the weight of the observation which is the inverse of the sampling probability. The weight can be interpreted as how many other possible observations this observation represent. A lower sampling probability means that there are probably fewer similar observations in the dataset, so each of these observations has to count more to account for this disrepancy.

In this plot the points representing the observations have a radius proportional to the inverse of the sampling probability, so as you can see the observations in the top have a much smaller chance of being chosen that the ones in the bottom part. The red line is the regression line fitted by normal linear regression while the blue line is fitted by a model which takes the design into account. 

As you can see, the blue line has a larger slope than the red line, indicating it gives the points in the top a bigger "weight" than the points in the bottom part to account for their lower sampling probabilities.


I will start by giving an introduction to survey statistics, where I will give the necessary background theory needed to be able to talk about linear regression in this context.

# Simple random sample

I will start by giving some definitions that we will need when talking about survey statistics.

* A *sampling unit* is one "element" we want to sample. In the case of a political survay for instance it would usually be one person.
* The *sampling population* is a set containing all the sampling units you are interested in. Continuing the example of political surveys the sampling population could be all people in the country eligible to vote in the next election.
* The *sampling frame* is the list of all sampling units you are going to sample from. Ideally the sampling frame and the sampling population would be the same, but that is not always to case. In some cases for example, you may not have a list of all the people who are eligible to vote, you may perhaps only have a list of the people who voted in the last election. This can cause a bias in the results.
* A *sample* is a subset of the sampling frame where we generally want to do some inference on information we get on the sampling units included in the sample.
* A *probability sample* is a sample where the elements sampling units included are chosen randomly.
* The *sampling probability* of a sampling unit is the probability that a specific sampling unit is included in the sample.

# Stratification

# Clustering

# Complex surveys

# Variance estimation (?)

# Regression
